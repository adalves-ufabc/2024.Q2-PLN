{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adalves-ufabc/2024.Q2-PLN/blob/main/2024_Q2_PLN_AULA_13_Notebook_24_Groq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6QILOdpOjwv"
      },
      "source": [
        "# **Processamento de Linguagem Natural [2024-Q2]**\n",
        "Prof. Alexandre Donizeti Alves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmK05FgcOzL2"
      },
      "source": [
        "## **LangChain**\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYKEbnlNTVlR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5885d55-42ae-4209-900b-fbcb841ae1eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.6/990.6 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.0/384.0 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.2/140.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#@title Instalando o pacote LangChain\n",
        "!pip install langchain -q U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJvs5RTcbE64",
        "outputId": "ebaae82b-c885-4b18-82c9-ade93c4cf56f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2.12\n"
          ]
        }
      ],
      "source": [
        "#@title Versão do LangChain\n",
        "\n",
        "import langchain\n",
        "\n",
        "print(langchain.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Integração com o pacote da Groq\n",
        "\n",
        "!pip install -qU langchain-groq"
      ],
      "metadata": {
        "id": "8klfbjqKbUpp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a96ebc6-0383-4364-d8f0-dc20d7c5d115"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/103.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.5/103.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/75.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/77.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/58.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RM5RnKClbPtQ",
        "outputId": "6850c88e-418e-4adf-ad54-05f0192d1cf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ],
      "source": [
        "#@title Definindo a chave da API da OpenAI\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = getpass.getpass()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Dados Estruturados**"
      ],
      "metadata": {
        "id": "6IyxUVl4sqaV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dados estruturados** são dados que são organizados e formatados de maneira sistemática, permitindo fácil acesso, análise e manipulação."
      ],
      "metadata": {
        "id": "s3YnWDZt4_Yj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Frequentemente é útil ter um modelo que retorne uma saída que corresponda a um esquema específico."
      ],
      "metadata": {
        "id": "qDFadJzXpfWq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Método `.with_structured_output()`**"
      ],
      "metadata": {
        "id": "LTG1jw9RpqhP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta é a maneira mais fácil e confiável de obter saídas estruturadas. O método `with_structured_output()` é implementado para modelos que fornecem APIs nativas para estruturar saídas, como chamadas de ferramentas/funções ou modo JSON, e utiliza essas capacidades internamente.\n",
        "\n",
        ">\n",
        "\n",
        "Este método recebe um esquema como entrada, que especifica os nomes, tipos e descrições dos atributos de saída desejados. O método retorna um `Runnable` semelhante a um modelo, exceto que, em vez de produzir strings ou Mensagens, ele produz objetos correspondentes ao esquema fornecido. O esquema pode ser especificado como uma classe `TypedDict`, um `JSON Schema` ou uma classe `Pydantic`. Se `TypedDict` ou `JSON Schema` forem usados, então um dicionário será retornado pelo `Runnable`, e se uma classe `Pydantic` for usada, então um objeto `Pydantic` será retornado.\n",
        "\n",
        ">\n",
        "\n",
        "Como exemplo, vamos fazer com que um modelo gere uma piada e separe a preparação do desfecho da piada:"
      ],
      "metadata": {
        "id": "ix6Cm19UpxIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "\n",
        "modelo = ChatGroq(model=\"llama3-70b-8192\", temperature=1.5)"
      ],
      "metadata": {
        "id": "V_YgIYt9RQH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classe `Pydantic`**\n",
        "\n",
        "Se quisermos que o modelo retorne um objeto `Pydantic`, basta passar a classe `Pydantic` desejada. A principal vantagem de usar `Pydantic` é que a saída gerada pelo modelo será validada. O `Pydantic` levantará um erro se algum campo obrigatório estiver faltando ou se algum campo for do tipo errado."
      ],
      "metadata": {
        "id": "3XPr8xwdq2o-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional\n",
        "\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "\n",
        "# Pydantic\n",
        "class Piada(BaseModel):\n",
        "    \"\"\"Piada para contar ao usuário.\"\"\"\n",
        "\n",
        "    introducao: str = Field(description=\"A introdução da piada\")\n",
        "    arremate: str = Field(description=\"O desfecho da piada\")\n",
        "    avaliacao: Optional[int] = Field(\n",
        "        default=None, description=\"Quão engraçada é a piada, de 1 a 10\"\n",
        "    )"
      ],
      "metadata": {
        "id": "XeU2r0ZNRub2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo_estruturado = modelo.with_structured_output(Piada)\n",
        "\n",
        "modelo_estruturado.invoke(\"Me conte uma piada sobre gatos\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNHCO6QZRyiO",
        "outputId": "62d79714-8945-42b3-f71c-85035d1df83b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Piada(introducao='Por que o gato foi ao médico?', arremate='Porque estava com um problema de saúde perrr-fecto!', avaliacao=8)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Além da estrutura da classe `Pydantic`, o nome da classe, a *docstring* e os nomes e as descrições fornecidas dos parâmetros são muito importantes. Na maioria das vezes, `with_structured_output` está usando a API de chamada de funções/ferramentas de um modelo, e você pode pensar efetivamente em todas essas informações como sendo adicionadas ao *prompt* do modelo."
      ],
      "metadata": {
        "id": "cKhTN5oEsTCh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`TypedDict` ou `JSON Schema`**\n",
        "\n",
        "Se você não quiser usar `Pydantic`, explicitamente não quiser validação dos argumentos ou quiser ser capaz de transmitir as saídas do modelo, pode definir seu esquema usando uma classe `TypedDict`. Opcionalmente, podemos usar uma sintaxe especial `Annotated` suportada pelo **LangChain**, que permite especificar o valor padrão e a descrição de um campo. Observe que o valor padrão não é preenchido automaticamente se o modelo não o gerar; ele é usado apenas na definição do esquema que é passado para o modelo."
      ],
      "metadata": {
        "id": "kaxvKPWBss8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import Annotated, TypedDict\n",
        "\n",
        "# TypedDict\n",
        "class Piada(TypedDict):\n",
        "    \"\"\"Piada para contar ao usuário.\"\"\"\n",
        "\n",
        "    introducao: Annotated[str, ..., \"introducao\"]\n",
        "    arremate: Annotated[str, ..., \"O desfecho da piada\"]\n",
        "    avaliacao: Annotated[Optional[int], None, \"Quão engraçada é a piada, de 1 a 10\"]"
      ],
      "metadata": {
        "id": "AyWxNISbSDDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo_estruturado = modelo.with_structured_output(Piada)\n",
        "\n",
        "modelo_estruturado.invoke(\"Me conte uma piada sobre gatos\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfPM0qZrSHMs",
        "outputId": "6bef224b-d55d-479a-99ce-3a51048ee362"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Piada(introducao='Por que os gatos sao incríveis?', arremate='porque são felizes de estarlá!', avaliacao=8)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "De maneira equivalente, podemos passar um dicionário `JSON Schema`. Isso não requer importações ou classes e torna muito claro como cada parâmetro é documentado, com o custo de ser um pouco mais verboso."
      ],
      "metadata": {
        "id": "eLoBmlzRuIq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "json_schema = {\n",
        "    \"title\": \"piada\",\n",
        "    \"description\": \"Piada para contar ao usuário.\",\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "        \"introducao\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"A introdução da piada\",\n",
        "        },\n",
        "        \"arremate\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"O desfecho da piada\",\n",
        "        },\n",
        "        \"avaliacao\": {\n",
        "            \"type\": \"integer\",\n",
        "            \"description\": \"Quão engraçada é a piada, de 1 a 10\",\n",
        "            \"default\": None,\n",
        "        },\n",
        "    },\n",
        "    \"required\": [\"introducao\", \"arremate\"],\n",
        "}\n"
      ],
      "metadata": {
        "id": "6QgVXkkpud3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo_estruturado = modelo.with_structured_output(json_schema)\n",
        "\n",
        "modelo_estruturado.invoke(\"Me conte uma piada sobre gatos\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUpPTbuSSO6n",
        "outputId": "058b7a16-c892-4b66-b63d-73c7c898004d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'introducao': 'Por que os gatos muito bons sempre fazem...',\n",
              " 'arremate': ' exigem alta remuneração'}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Escolhendo entre múltiplos esquemas**"
      ],
      "metadata": {
        "id": "9_uEqzTGvBPx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A maneira mais simples de permitir que o modelo escolha entre vários esquemas é criar um esquema \"pai\" que tenha um atributo do tipo `Union`:"
      ],
      "metadata": {
        "id": "1Hz00jHevIoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Union\n",
        "\n",
        "# Pydantic\n",
        "\n",
        "class Piada(BaseModel):\n",
        "    \"\"\"Piada para contar ao usuário.\"\"\"\n",
        "\n",
        "    introducao: str = Field(description=\"A introdução da piada\")\n",
        "    arremate: str = Field(description=\"O desfecho da piada\")\n",
        "    avaliacao: Optional[int] = Field(\n",
        "        default=None, description=\"Quão engraçada é a piada, de 1 a 10\"\n",
        "    )\n",
        "\n",
        "class RespostaConversacional(BaseModel):\n",
        "    \"\"\"Responda de maneira conversacional. Seja gentil e prestativo.\"\"\"\n",
        "\n",
        "    resposta: str = Field(description=\"Uma resposta conversacional à pergunta do usuário\")\n",
        "\n",
        "class Resposta(BaseModel):\n",
        "    saida: Union[Piada, RespostaConversacional]"
      ],
      "metadata": {
        "id": "4It9eSpCSXT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo_estruturado = modelo.with_structured_output(Resposta)\n",
        "\n",
        "resposta = modelo_estruturado.invoke(\"Me conte uma piada sobre gatos\")"
      ],
      "metadata": {
        "id": "YyQZ9rEFSaTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resposta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yX4wPoOwwWnp",
        "outputId": "317036c2-b1b2-4cd3-c91f-83fa8db87e30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Resposta(saida=Piada(introducao='Perdi meu gato.', arremate='Mas ele na verdade não sabia quem ele erazelf', avaliacao=10))"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resposta.saida"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-nV0FhDwdJq",
        "outputId": "65d39b27-9d3c-41d2-ec81-81da1af7504c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Piada(introducao='Perdi meu gato.', arremate='Mas ele na verdade não sabia quem ele erazelf', avaliacao=10)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resposta.saida.introducao"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "w5SWiT88wiqg",
        "outputId": "0ee2fee0-8175-4bc8-ded3-4b663fe114e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Perdi meu gato.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resposta = modelo_estruturado.invoke(\"Como você está hoje?\")"
      ],
      "metadata": {
        "id": "p-J3wN4QSfW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resposta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBj-gOZ5L6pE",
        "outputId": "db15ef2d-3057-4b87-8c85-689b5147d92e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Resposta(saida=RespostaConversacional(resposta='Eu estouoperative!'))"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Few-shot prompting***"
      ],
      "metadata": {
        "id": "iozPUz_PyUnp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Few-shot prompting*** é uma técnica onde se fornecem alguns exemplos específicos no *prompt* para guiar o modelo na geração de respostas. Em vez de treinar o modelo com uma nova base de dados completa, você apenas inclui alguns exemplos relevantes diretamente no *prompt*."
      ],
      "metadata": {
        "id": "-lA-SqH2yz_n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para esquemas mais complexos, é muito útil adicionar exemplos ao *prompt*.\n",
        "\n",
        "A maneira mais simples e universal é adicionar exemplos a uma mensagem do sistema no *prompt*:"
      ],
      "metadata": {
        "id": "x2SVsWbDyMit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "sistema = \"\"\"Você é um comediante hilário. Sua especialidade são piadas do tipo \"knock-knock\".\n",
        "Retorne uma piada que tenha a introdução (a resposta para \"Quem está aí?\") e o arremate final (a resposta para \"<introdução> quem?\").\n",
        "\n",
        "Aqui estão alguns exemplos de piadas:\n",
        "\n",
        "exemplo_usuario: Me conte uma piada sobre gatos\n",
        "exemplo_assistente: {{\"introducao\": \"Por que os gatos não jogam cartas?\", \"arremate\": \"Porque eles têm medo dos cães que podem trapacear!\", \"avaliacao\": 8}}\n",
        "\n",
        "exemplo_usuario: Conte outra piada sobre cães\n",
        "exemplo_assistente: {{\"introducao\": \"Por que os cães levam uma bola para a escola?\", \"arremate\": \"Porque eles querem aprender a jogar!\", \"ratavaliacaoing\": 7}}\n",
        "\n",
        "exemplo_usuario: Agora sobre peixes\n",
        "exemplo_assistente: {{\"introducao\": \"Por que o peixe foi ao banco?\", \"arremate\": \"Para abrir uma conta corrente!\", \"avaliacao\": 9}}\"\"\"\n",
        "\n",
        "# template de prompt\n",
        "prompt = ChatPromptTemplate.from_messages([(\"system\", sistema), (\"human\", \"{input}\")])\n",
        "\n",
        "# uso do prompt com um modelo estruturado\n",
        "modelo_estruturado_few_shot = prompt | modelo_estruturado\n",
        "\n",
        "modelo_estruturado_few_shot.invoke(\"Me conte uma piada sobre elefantes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4rFakRh0kYC",
        "outputId": "4e10015d-2a47-46f9-88b9-3fdd44ae24fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Resposta(saida=Piada(introducao='Quem está ai?', arremate='Cantor, porque tem muita tromba!', avaliacao=8))"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Outro exemplo:"
      ],
      "metadata": {
        "id": "7ee9wq0Y2P4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pydantic\n",
        "\n",
        "class Produto(BaseModel):\n",
        "    \"\"\"Descrição de um produto.\"\"\"\n",
        "\n",
        "    nome: str = Field(description=\"O nome do produto\")\n",
        "    descricao: str = Field(description=\"A descrição do produto\")"
      ],
      "metadata": {
        "id": "QMMaTjab28rB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo_estruturado = modelo.with_structured_output(Produto)"
      ],
      "metadata": {
        "id": "rQpTkm6F3LQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "sistema = \"\"\"Você é um redator de descrições de produtos experiente. Sua tarefa é criar descrições detalhadas e envolventes para produtos.\n",
        "Cada descrição deve incluir informações sobre as principais características e benefícios do produto.\n",
        "\n",
        "Aqui estão alguns exemplos de descrições:\n",
        "\n",
        "exemplo_usuario: Descreva um smartphone moderno\n",
        "exemplo_assistente: {{\"nome\": \"Smartphone UltraX\", \"descricao\": \"O Smartphone UltraX é equipado com uma tela AMOLED de 6,7 polegadas, processador octa-core de última geração e câmera tripla de 64MP. Oferece um desempenho rápido e uma experiência de usuário excepcional com bateria de longa duração e carregamento rápido.\"}}\n",
        "\n",
        "exemplo_usuario: Descreva um aspirador de pó robô\n",
        "exemplo_assistente: {{\"nome\": \"Aspirador Robô CleanPro\", \"descricao\": \"O Aspirador Robô CleanPro é ideal para manter sua casa limpa sem esforço. Com tecnologia de navegação inteligente, ele limpa todos os cantos e vem com um sistema de filtragem HEPA que captura alérgenos e poeira. Compacto e silencioso, é fácil de usar e programar.\"}}\n",
        "\n",
        "exemplo_usuario: Agora sobre uma cafeteira\n",
        "exemplo_assistente: {{\"nome\": \"Cafeteira Espresso Elite\", \"descricao\": \"A Cafeteira Espresso Elite oferece uma experiência de café de qualidade barista no conforto de sua casa. Com um sistema de pressão de 15 bar, ela extrai o máximo sabor dos grãos. Possui um moinho integrado e controle de temperatura preciso para preparar o café perfeito a cada vez.\"}}\"\"\"\n",
        "\n",
        "# template de prompt\n",
        "prompt = ChatPromptTemplate.from_messages([(\"system\", sistema), (\"human\", \"{input}\")])\n",
        "\n",
        "# uso do prompt com um modelo estruturado\n",
        "modelo_estruturado_few_shot = prompt | modelo_estruturado\n",
        "\n",
        "modelo_estruturado_few_shot.invoke(\"Descreva um tablet moderno\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KlnXwtc2RSd",
        "outputId": "8fb51b38-9341-47be-df38-0fa2b5f3c0ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Produto(nome='Tablet ProX', descricao='O Tablet ProX é uma powerful ferramenta portátil para trabalho e entretenimento. Equipado com uma tela IPS de 12,3 polegadas em resolução 4K, processador de quarta geração e cartão gráfico integrado, é ideal para navegar, assistir vídeos, jogar e realizar multitarefa com facilidade. Sua bateria de longa duração e design moderno slim o tornam perfeito para carro, bolsa ou mochila.')"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para modelos que suportam mais de um meio de estruturar saídas, você pode especificar qual método usar com o argumento `method=`."
      ],
      "metadata": {
        "id": "wkt2Pm_p5SSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo_estruturado = modelo.with_structured_output(None, method=\"json_mode\")\n",
        "\n",
        "modelo_estruturado.invoke(\n",
        "    \"Descreva um tablet moderno, responda em JSON com as chaves `nome` e `descricao`\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6mOsAWuS43A",
        "outputId": "93b63ac7-0da7-43c4-afea-60bb8cddb71f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'nome': '(Tablet High-Tech',\n",
              " 'descricao': ' Tablet de alta performance com tela touchscreen de 10,1 polegadas, processoador quad-core de 2,3 GHz, 4GB de RAM e 64GB de armazenamento interno expandível até 1TB via cartão microSD. Câmera traseira de 13MP com flash LED e câmera frontal de 5MP. Tecnologia de recursos de fingerprint, conexão Wi-Fi 6 e bateria de longa duração de até 12 horas.'}"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelos de linguagem não são perfeitos ao gerar saídas estruturadas, especialmente quando os esquemas se tornam complexos. Você pode evitar a geração de exceções e lidar com a saída bruta você mesmo passando `include_raw=True`. Isso altera o formato da saída para conter a mensagem bruta, o valor analisado (se bem-sucedido) e quaisquer erros resultantes."
      ],
      "metadata": {
        "id": "1h3UqxgM6Ch3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo_estruturado = modelo.with_structured_output(Produto, include_raw=True)\n",
        "\n",
        "modelo_estruturado.invoke(\"Descreva um tablet moderno\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXuncLbSS_dw",
        "outputId": "2ba41694-a89c-4758-cfc8-3317e45e90f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'raw': AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_snaq', 'function': {'arguments': '{\"nome\":\"Tablet Moderno\",\"descricao\":\"Um tablet moderno e um dispositivoelectronico portatil que combina as funcionalidades de um computador com a portabilidade de umsmartphone. Possui uma telatouchscreen de alta resolucao, processador potente, memória RAM abundante e armazenamento interno sufficeiciente para gravar arquivos, utilizar aplikacoes e outras funcionalidades.\"}', 'name': 'Produto'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 128, 'prompt_tokens': 847, 'total_tokens': 975, 'completion_time': 0.418084027, 'prompt_time': 0.073134998, 'queue_time': None, 'total_time': 0.49121902500000003}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_753a4aecf6', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-14c7c2a6-abaf-41d0-b145-26c6b982ef4d-0', tool_calls=[{'name': 'Produto', 'args': {'nome': 'Tablet Moderno', 'descricao': 'Um tablet moderno e um dispositivoelectronico portatil que combina as funcionalidades de um computador com a portabilidade de umsmartphone. Possui uma telatouchscreen de alta resolucao, processador potente, memória RAM abundante e armazenamento interno sufficeiciente para gravar arquivos, utilizar aplikacoes e outras funcionalidades.'}, 'id': 'call_snaq', 'type': 'tool_call'}], usage_metadata={'input_tokens': 847, 'output_tokens': 128, 'total_tokens': 975}),\n",
              " 'parsed': Produto(nome='Tablet Moderno', descricao='Um tablet moderno e um dispositivoelectronico portatil que combina as funcionalidades de um computador com a portabilidade de umsmartphone. Possui uma telatouchscreen de alta resolucao, processador potente, memória RAM abundante e armazenamento interno sufficeiciente para gravar arquivos, utilizar aplikacoes e outras funcionalidades.'),\n",
              " 'parsing_error': None}"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Referência**:\n",
        "\n",
        "> https://python.langchain.com/v0.2/docs/how_to/structured_output/"
      ],
      "metadata": {
        "id": "k3Tkx9VP4Sjf"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4OOHFBgKafiqW765945rn",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}