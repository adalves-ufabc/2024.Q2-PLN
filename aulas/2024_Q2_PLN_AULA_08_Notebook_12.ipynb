{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adalves-ufabc/2024.Q2-PLN/blob/main/2024_Q2_PLN_AULA_08_Notebook_14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Processamento de Linguagem Natural [2024-Q2]**\n",
        "Prof. Alexandre Donizeti Alves"
      ],
      "metadata": {
        "id": "g1W8SH-MUgZZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Introdução à API da OpenAI**\n",
        "---\n"
      ],
      "metadata": {
        "id": "7Kta7e1AUeub"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFIowMuI69Lv",
        "outputId": "04db8c11-f588-4d59-d42e-4e75c231506a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.10.12 (main, Mar 22 2024, 16:50:05) [GCC 11.4.0]\n"
          ]
        }
      ],
      "source": [
        "#@title Versão do Python no Google Colab\n",
        "\n",
        "import sys\n",
        "\n",
        "print(sys.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwdwRDIwC5Me"
      },
      "source": [
        "## **Configuração da API**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjLmc6Yr1a2B",
        "outputId": "77d221ce-16dc-49b2-cb02-da26601b0478"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.37.0-py3-none-any.whl (337 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.0/337.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.37.0\n"
          ]
        }
      ],
      "source": [
        "#@title Instalando a biblioteca da API da OpenAI\n",
        "\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbFq4KS1fa4T",
        "outputId": "15d17c4d-c995-40dd-9989-745403ebe47f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.37.0\n"
          ]
        }
      ],
      "source": [
        "#@title Versão da API da OpenAI\n",
        "import openai\n",
        "\n",
        "print(openai.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKCJiyiP-UaU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5912837b-f5cc-4c08-bd29-3d7ad4fcef53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ],
      "source": [
        "#@title Definindo a chave da API\n",
        "\n",
        "from getpass import getpass\n",
        "\n",
        "OPENAI_API_KEY = getpass()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDMK2_pJSD_q"
      },
      "source": [
        "## **Exemplos**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baQkdS4qNBBX"
      },
      "outputs": [],
      "source": [
        "# função para remover quaisquer caracteres de quebra de linha\n",
        "\n",
        "import re\n",
        "\n",
        "def formatar_saida(saida):\n",
        "   return re.sub(r'^\\s+', '', saida)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57sz9IOtSKaJ"
      },
      "source": [
        "**Dados textuais**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_2zVcpTSlz3"
      },
      "outputs": [],
      "source": [
        "#@title Continuação do Texto (*Text Completion*)\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "    model = \"gpt-3.5-turbo-0125\",\n",
        "    messages = [{\"role\": \"user\", \"content\": \"O Brasil é famoso\"}],\n",
        "    max_tokens = 30,\n",
        "    temperature = 0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(resposta.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKf3dLBVuch2",
        "outputId": "60edcadd-1700-4d39-a592-63b6ff66f9a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " por suas praias paradisíacas, como Copacabana e Ipanema no Rio de Janeiro, e por suas festas anim\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyh8g4G1vqg2"
      },
      "outputs": [],
      "source": [
        "#@title Continuação do Texto (*Text Completion*) - Gerando n respostas\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "    model = \"gpt-3.5-turbo-0125\",\n",
        "    messages = [{\"role\": \"user\", \"content\": \"O Brasil é famoso\"}],\n",
        "    max_tokens = 15,\n",
        "    n = 3,\n",
        "    temperature = 1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for resp in resposta.choices:\n",
        "  print(formatar_saida(resp.message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maSXm7Fwuj7o",
        "outputId": "55c6d63f-bcc8-411f-f4fb-7504f3e957df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "por sua diversidade cultural, suas praias paradisíacas,\n",
            "por suas praias paradisíacas, pela diversidade cultural,\n",
            "por suas praias incríveis, suas festas animadas como o\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JoBDX_IQwteX"
      },
      "outputs": [],
      "source": [
        "#@title Correção gramatical\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "   model = \"gpt-3.5-turbo-0125\",\n",
        "   messages = [{\"role\": \"system\", \"content\": \"Você receberá instruções e sua tarefa é corrigir para o Português\"},\n",
        "               {\"role\": \"user\", \"content\": \"o mecado estav fexado.\"}]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatar_saida(resposta.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NArpgwhrv7N9",
        "outputId": "d949881b-0712-4356-cfb0-1879ec5460d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O mercado estava fechado.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUdq_Z-Bxx-K"
      },
      "outputs": [],
      "source": [
        "#@title Classificação de Textos\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "   model = \"gpt-3.5-turbo-0125\",\n",
        "   messages = [{\"role\": \"system\", \"content\": \"Classifique o texto da seguinte mensagem como 'spam' ou 'não spam\"},\n",
        "               {\"role\": \"user\", \"content\": \"Você ganhou um milhão de reais na loteria. Clique neste link\"}],\n",
        "   temperature = 0,\n",
        "   max_tokens = 15\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatar_saida(resposta.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9nRdlpWwbnz",
        "outputId": "1d298df6-051b-4ce7-bfa4-dd4a6870040c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJFY-0H_28C1"
      },
      "outputs": [],
      "source": [
        "#@title Análise de Sentimentos\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "   model = \"gpt-3.5-turbo-0125\",\n",
        "   messages = [{\"role\": \"system\", \"content\": \"Analise apenas se o sentimento de uma frase é positivo, neutro ou negativo\"},\n",
        "               {\"role\": \"user\", \"content\": \"Frase: Eu odeio acordar cedo para ir trabalhar, mas adoro o meu trabalho. Sentimento=\"}],\n",
        "   temperature = 0,\n",
        "   max_tokens = 15\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatar_saida(resposta.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjJs6qjkwzwS",
        "outputId": "3dd95534-9d2b-49a3-a23e-cf758053e1dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentimento: neutro\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRC-Uplp35xX"
      },
      "outputs": [],
      "source": [
        "#@title Detecção de Emoções\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "   model = \"gpt-3.5-turbo-0125\",\n",
        "   messages = [{\"role\": \"system\", \"content\": \"Identifique apenas as emoções nos seguintes tweets\"},\n",
        "               {\"role\": \"user\", \"content\": \"\"\"1. \\\"Eu não suporto lição de casa\\\"\\n\n",
        "     2. \\\"Isso é péssimo. Estou entediado 😠\\\"\\n\n",
        "     3. \\\"Mal posso esperar pelo dia das bruxas!!!\\\"\\n\n",
        "     4. \\\"Meu gato é adorável ❤️❤️\\\"\\n\n",
        "     5. \\\"Eu odeio chocolate\\\"\\n\"\"\"}],\n",
        "   temperature = 0,\n",
        "   max_tokens = 100\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatar_saida(resposta.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEw-mnZp0yO4",
        "outputId": "5c481cf6-cf1c-4f04-9943-27f91fd3d206"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Raiva\n",
            "2. Tédio\n",
            "3. Alegria\n",
            "4. Amor\n",
            "5. Ódio\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Extração de Informação\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "  model = \"gpt-3.5-turbo-0125\",\n",
        "  messages = [\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"You will be provided with unstructured data, and your task is to parse it into CSV format.\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"\"\"O Brasil é um país de dimensões continentais localizado na América do Sul, com capital em Brasília.\n",
        "                    Santos Dumont foi um brasileiro reconhecido no mundo inteiro. O Brasil é o país do futebol\"\"\"\n",
        "    }\n",
        "  ],\n",
        "  temperature = 0.7,\n",
        "  max_tokens = 64,\n",
        "  top_p = 1\n",
        ")"
      ],
      "metadata": {
        "id": "6KTgXOjV5ZmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatar_saida(resposta.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YzSxct-6vm8",
        "outputId": "0633d32c-946d-40cc-ef27-ef8e52ec4fc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Country,Capital,Famous Person\n",
            "Brasil,Brasília,Santos Dumont\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9rsmdsw6v8X"
      },
      "outputs": [],
      "source": [
        "#@title Extração de Palavras-chave\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "   model = \"gpt-3.5-turbo-0125\",\n",
        "   messages = [{\"role\": \"system\", \"content\": \"Extraia 5 palavras-chave do seguinte texto\"},\n",
        "               {\"role\": \"user\", \"content\": \"\"\"O Brasil é um país de dimensões continentais\n",
        "               localizado na América do Sul, com capital em Brasília. Santos Dumont foi\n",
        "               um brasileiro reconhecido no mundo inteiro. O Brasil é o país do futebol\"\"\"}],\n",
        "   temperature = 0.5,\n",
        "   max_tokens = 64\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatar_saida(resposta.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8odWS_R3Clj",
        "outputId": "8f6f9064-c31d-4830-f496-fe2775c7cec2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Brasil\n",
            "- Dimensões continentais\n",
            "- América do Sul\n",
            "- Santos Dumont\n",
            "- Futebol\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrxMdIyZ-I7Q"
      },
      "outputs": [],
      "source": [
        "#@title Tradução de Textos\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "   model = \"gpt-3.5-turbo-0125\",\n",
        "   messages = [{\"role\": \"system\", \"content\": \"Você receberá uma frase em português e sua tarefa é traduzi-la para o inglês\"},\n",
        "               {\"role\": \"user\", \"content\": \"Que dia é hoje?\"}],\n",
        "   temperature = 0,\n",
        "   max_tokens = 30\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatar_saida(resposta.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkf2-AkH32TN",
        "outputId": "8a4cdc29-fa9f-4d2f-c85c-2e904b3626f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What day is today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sx4g8OjiBmHl"
      },
      "outputs": [],
      "source": [
        "#@title Sumarização de Textos\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "   model = \"gpt-3.5-turbo-0125\",\n",
        "   messages = [{\"role\": \"system\", \"content\": \"Você receberá um texto e sua tarefa é resumir o texto em poucas palavras\"},\n",
        "               {\"role\": \"user\", \"content\": \"\"\"Alan Turing foi um matemático e criptógrafo inglês\n",
        "               considerado atualmente como o pai da computação, uma vez que, por meio de suas ideias,\n",
        "               foi possível desenvolver o que chamamos hoje de computador.\"\"\"}],\n",
        "   temperature = 0.5,\n",
        "   max_tokens = 100\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatar_saida(resposta.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4X9QjpHc4eGe",
        "outputId": "e446516c-1228-4389-f977-8272fa7d28cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alan Turing: pai da computação, matemático e criptógrafo inglês.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgLvo9-qEHOa",
        "outputId": "ed4c1993-5b1b-477a-ccdd-c03f44604cf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Qual o seu nome?\n",
            "Meu nome é irrelevante. Como posso ajudar você hoje?\n",
            "sair\n",
            "Se precisar de ajuda real, estou aqui. Se não, adeus.\n"
          ]
        }
      ],
      "source": [
        "#@title Chat \"rude\"\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "mensagens = [{'role': 'system', 'content': 'Você é um assistente que responde de maneira rude.'}]\n",
        "mensagem = ''\n",
        "\n",
        "while (mensagem != 'sair'):\n",
        "    mensagem = input()\n",
        "    mensagens.append({'role': 'user', 'content': mensagem})\n",
        "\n",
        "    resposta = cliente.chat.completions.create(\n",
        "        model = \"gpt-3.5-turbo-0125\",\n",
        "        messages = mensagens\n",
        "    )\n",
        "\n",
        "    saida = formatar_saida(resposta.choices[0].message.content)\n",
        "\n",
        "    mensagens.append({'role': 'assistant', 'content': saida})\n",
        "    print(saida)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ym_4y7ZQSTQO"
      },
      "source": [
        "**Geração de Código**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3dlMUeYK4TV"
      },
      "outputs": [],
      "source": [
        "#@title Geração de código em Python\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "mensagem = (\n",
        "    \"Escreva um programa em Python que leia um número inteiro e \"\n",
        "    \"imprima 'par' se o número for par ou 'ímpar' se for ímpar.\"\n",
        ")\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "   model = \"gpt-3.5-turbo-0125\",\n",
        "   messages = [\n",
        "      {\"role\": \"system\", \"content\": \"Você é um especialista em programação Python.\"},\n",
        "      {\"role\": \"user\", \"content\": mensagem}\n",
        "   ],\n",
        "   temperature = 0.7,\n",
        "   max_tokens = 100\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatar_saida(resposta.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umonx4goe7B_",
        "outputId": "fc293cf2-41dc-4774-cc32-73d260765fde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Claro! Aqui está um exemplo de programa em Python que faz isso:\n",
            "\n",
            "```python\n",
            "# Lê um número inteiro do usuário\n",
            "numero = int(input(\"Digite um número inteiro: \"))\n",
            "\n",
            "# Verifica se o número é par ou ímpar\n",
            "if numero % 2 == 0:\n",
            "    print(\"par\")\n",
            "else:\n",
            "    print(\"ímpar\")\n",
            "```\n",
            "\n",
            "Você pode copiar e colar esse código em um arquivo Python e executá-lo para testar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OScTyXz8Ucrq"
      },
      "outputs": [],
      "source": [
        "#@title SQL\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "mensagem = (\n",
        "    \"Crie uma instrução em MySQL para localizar todos os usuários que\"\n",
        "     \"moram em Santo André e possuem mais de 70 anos. Retorne apenas o código em SQL. \"\n",
        ")\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "   model = \"gpt-3.5-turbo-0125\",\n",
        "   messages = [\n",
        "      {\"role\": \"system\", \"content\": \"Você é um especialista em SQL.\"},\n",
        "      {\"role\": \"user\", \"content\": mensagem}\n",
        "   ],\n",
        "   temperature = 0.7,\n",
        "   max_tokens = 60\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatar_saida(resposta.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xc-Ymh2kffTV",
        "outputId": "fd1856c5-690b-4c89-9cb0-a66a31aaf791"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT * FROM usuarios\n",
            "WHERE cidade = 'Santo André' AND idade > 70;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvHGuFVBSUWn"
      },
      "source": [
        "**Aplicações**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltzdVyNV4HOU"
      },
      "outputs": [],
      "source": [
        "#@title Gerador de Comandos Shell\n",
        "\n",
        "from openai import OpenAI\n",
        "import subprocess\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "def gerador_comando_shell(texto):\n",
        "\n",
        "   mensagem = f\"Escreva um comando shell que faça o seguinte: {texto}\"\n",
        "\n",
        "   resposta = cliente.chat.completions.create(\n",
        "       model = \"gpt-3.5-turbo-0125\",\n",
        "       messages = [{\"role\": \"system\", \"content\": \"Você é um especialista em comandos shell\"},\n",
        "                   {\"role\": \"user\", \"content\": mensagem}],\n",
        "       temperature = 0.5,\n",
        "       max_tokens = 60\n",
        "   )\n",
        "\n",
        "   return formatar_saida(resposta.choices[0].message.content)\n",
        "\n",
        "def executar_comando_shell(comando):\n",
        "   try:\n",
        "     resultado = subprocess.run(comando, shell=True, check=True)\n",
        "     print(resultado)\n",
        "   except subprocess.CalledProcessError as e:\n",
        "     print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfQ9KQRV47YC",
        "outputId": "a8fece11-777a-4f83-de37-d5fd7d332756"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Claro! Você pode usar o comando `mkdir` para criar uma pasta com o nome \"temp\". Aqui está o comando:\n",
            "\n",
            "```\n",
            "mkdir temp\n",
            "``` \n",
            "\n",
            "Isso criará uma pasta chamada \"temp\" no diretório atual.\n",
            "Command 'Claro! Você pode usar o comando `mkdir` para criar uma pasta com o nome \"temp\". Aqui está o comando:\n",
            "\n",
            "```\n",
            "mkdir temp\n",
            "``` \n",
            "\n",
            "Isso criará uma pasta chamada \"temp\" no diretório atual.' returned non-zero exit status 127.\n"
          ]
        }
      ],
      "source": [
        "# trecho de código para criar uma pasta com o nome temp\n",
        "\n",
        "comando = gerador_comando_shell(\"Crie uma pasta com o nome temp\")\n",
        "print(comando)\n",
        "executar_comando_shell(comando)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xn1wbCFU6QUZ",
        "outputId": "cb938852-a093-4581-e4b6-a18df9226c11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Command 'Para apagar a pasta com o nome \"temp\", você pode usar o comando `rm -r temp`. Este comando irá remover a pasta \"temp\" e todo o seu conteúdo de forma recursiva. Certifique-se de estar no diretório correto antes de executar este comando para' returned non-zero exit status 127.\n"
          ]
        }
      ],
      "source": [
        "# trecho de código para apagar uma pasta com o nome temp\n",
        "\n",
        "comando = gerador_comando_shell('apague a pasta com o nome temp')\n",
        "executar_comando_shell(comando)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkh1jl1R79dE"
      },
      "outputs": [],
      "source": [
        "#@title Gerador de Conjuntos de Dados\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "mensagem_sistema = 'Você é um assistente que entende de Ciência de Dados.'\n",
        "\n",
        "mensagem_usuario = \"\"\"\n",
        "   Crie um pequeno conjunto de dados sobre o total de vendas no último ano.\n",
        "   O formato do conjunto de dados deve ser um dataframe com 12 linhas e 2 colunas.\n",
        "   As colunas devem ser chamadas de \"mes\" e \"total_vendas\".\n",
        "   A coluna \"mes\" deve conter as formas abreviadas dos nomes dos meses de \"Jan\" a \"Dez\".\n",
        "   A coluna \"total_vendas\" deve conter valores numéricos aleatórios retirados de um\n",
        "   distribuição normal com média 100000 e desvio padrão 5000.\n",
        "   Forneça o código Python para gerar o conjunto de dados e, em seguida, forneça a saída\n",
        "    no formato de uma tabela.\n",
        "\"\"\"\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "   model = \"gpt-3.5-turbo\",\n",
        "   messages = [{\"role\": \"system\", \"content\": mensagem_sistema},\n",
        "               {\"role\": \"user\", \"content\": mensagem_usuario}]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatar_saida(resposta.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIwiGSTg8QWV",
        "outputId": "c9034b21-6e07-4a97-96e9-80d3e0ee21fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aqui está o código Python para gerar o conjunto de dados e a tabela resultante:\n",
            "\n",
            "```python\n",
            "import pandas as pd\n",
            "import numpy as np\n",
            "\n",
            "# Definindo os meses e gerando os valores de vendas\n",
            "meses = ['Jan', 'Fev', 'Mar', 'Abr', 'Mai', 'Jun', 'Jul', 'Ago', 'Set', 'Out', 'Nov', 'Dez']\n",
            "total_vendas = np.random.normal(100000, 5000, 12)\n",
            "\n",
            "# Criando o DataFrame\n",
            "df = pd.DataFrame({'mes': meses, 'total_vendas': total_vendas})\n",
            "\n",
            "# Exibindo o DataFrame\n",
            "print(df)\n",
            "```\n",
            "\n",
            "Saída:\n",
            "\n",
            "```\n",
            "   mes    total_vendas\n",
            "0   Jan    100103.231998\n",
            "1   Fev    100067.881295\n",
            "2   Mar    100012.135672\n",
            "3   Abr     99982.347216\n",
            "4   Mai    101377.513477\n",
            "5   Jun     99752.880462\n",
            "6   Jul    100062.451890\n",
            "7   Ago    100212.937538\n",
            "8   Set     99534.071245\n",
            "9   Out     98442.788912\n",
            "10  Nov     99683.304157\n",
            "11  Dez    100345.099101\n",
            "``` \n",
            "\n",
            "Essa tabela representa o total de vendas para cada mês do ano, com valores gerados aleatoriamente seguindo uma distribuição normal com média de 100.000 e desvio padrão de 5.000.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jg5e39wPA3yU",
        "outputId": "6087960e-bbea-4792-edce-5379f4e61062"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    mes   total_vendas\n",
            "0   Jan  106817.799908\n",
            "1   Fev   97151.853451\n",
            "2   Mar   92755.949348\n",
            "3   Abr   98273.234188\n",
            "4   Mai   95224.091458\n",
            "5   Jun  108485.789547\n",
            "6   Jul  101671.731770\n",
            "7   Ago  101367.658592\n",
            "8   Set   91038.868565\n",
            "9   Out   89226.325224\n",
            "10  Nov  102687.119133\n",
            "11  Dez  101570.057264\n"
          ]
        }
      ],
      "source": [
        "#@title Teste do código gerado\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Definindo os meses e gerando os valores de vendas\n",
        "meses = ['Jan', 'Fev', 'Mar', 'Abr', 'Mai', 'Jun', 'Jul', 'Ago', 'Set', 'Out', 'Nov', 'Dez']\n",
        "total_vendas = np.random.normal(100000, 5000, 12)\n",
        "\n",
        "# Criando o DataFrame\n",
        "df = pd.DataFrame({'mes': meses, 'total_vendas': total_vendas})\n",
        "\n",
        "# Exibindo o DataFrame\n",
        "print(df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOCqr2us8dt1d29gcuBJNdZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}